# LLM提供商配置
LLM_PROVIDER=ollama
LLM_MODEL=llama2  # 或你使用的其他模型名称

# Ollama配置 - 通过SSH端口转发
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_TIMEOUT=120  # 请求超时时间(秒)
OLLAMA_RETRY_COUNT=3  # 连接失败时的重试次数
OLLAMA_RETRY_DELAY=2  # 重试间隔时间(秒)

# 向量数据库配置 - 默认使用本地Qdrant
VECTOR_STORE_TYPE=qdrant
QDRANT_HOST=localhost
QDRANT_PORT=6333

# 其他配置
SERVICE_HOST=0.0.0.0
SERVICE_PORT=8002
DEBUG_MODE=true 